{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment - Probabilistic Graphical Models\n",
    "### Year 2020-2021- Semester I\n",
    "### CCE5225\n",
    "####  Developed by - Adrian Muscat, 2020\n",
    "---\n",
    "Zachary Cauchi, 197999M, BSc CS, Yr I\n",
    "\n",
    "Submit a pdf version (with the attached plagiarism form) of the final jupyter notebook (as a turn-it-in job on VLE) and the jupyter notebook itself separately (as an assignment job on VLE)\n",
    "\n",
    "This assignment is to be attempted individually. It is essential that the work you submit and present consists only of your own work; use of copied material will be treated as plagiarism. Discussion is only permitted on general issues, and it is absolutely forbidden to discuss specific details with anyone and/or share results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, MultiLabelBinarizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import classification_report, multilabel_confusion_matrix\n",
    "\n",
    "import pandas\n",
    "from collections import Counter\n",
    "\n",
    "import re\n",
    "\n",
    "def saveAnswer(obj, name):\n",
    "    answer_file = open(f'saved_answers/{name}.pkl', 'wb')\n",
    "    pickle.dump(obj, answer_file)\n",
    "    answer_file.close()\n",
    "\n",
    "def trimSubClasses(labels):\n",
    "    pattern = re.compile(r'.+?(?=_\\d+(?!.))')\n",
    "    labels = [[label if not pattern.match(label) else pattern.match(label).group(0) for label in row] for row in labels]\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = open('MLC_data_2020_21.pkl','rb')\n",
    "data = pickle.load(infile, encoding='latin1')\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "First split is into : dict_keys(['development', 'test']) \n\nThe three lists are dict_keys(['object_labels', 'output_labels', 'geometric_features']) \n\nThere are 4253 examples in dev set\n\nFirst example:\n['2008_001130.jpg', 'tvmonitor', 'bottle']\n['next_to', 'at_the_level_of', 'near']\n[ 0.68888274  0.07051991  0.          0.88679245  0.39215686  0.63316053\n  0.109375    1.36170213  1.14893617  1.06603774  0.58490566  9.76862745\n  0.5546875  -0.30530973]\n\nSecond example:\n['2008_002210.jpg', 'person', 'diningtable']\n['behind', 'opposite', 'near']\n[ 0.43984962  0.28696742  0.16        0.40206186  2.36082474  0.48306117\n  0.          2.27350427  0.31623932  1.          0.66666667  1.53275109\n  0.34962406 -0.33333333]\n\n...\n"
     ]
    }
   ],
   "source": [
    "# Explore dataset\n",
    "print(\"First split is into :\",data.keys(),'\\n')\n",
    "#\n",
    "# Lets explore the development set\n",
    "# This is organised into three lists\n",
    "print(\"The three lists are\",data['development'].keys(),'\\n')\n",
    "#\n",
    "# The first element of each list corresponds to the object_labels, \n",
    "# geomteric features and output labels for the first example\n",
    "# ...and so on\n",
    "# When getting the object labels, trim them accordingly to obtain only the 20 classes\n",
    "train_obj_labels = trimSubClasses(data['development']['object_labels'])\n",
    "train_out_labels = data['development']['output_labels']\n",
    "train_geo_feat = data['development']['geometric_features']\n",
    "test_obj_labels = trimSubClasses(data['test']['object_labels'])\n",
    "test_out_labels = data['test']['output_labels']\n",
    "test_geo_feat = data['test']['geometric_features']\n",
    "\n",
    "print(\"There are\",len(train_obj_labels), \"examples in dev set\\n\")\n",
    "print(\"First example:\")\n",
    "print(train_obj_labels[0])\n",
    "print(train_out_labels[0])\n",
    "print(train_geo_feat[0])\n",
    "print(\"\\nSecond example:\")\n",
    "print(train_obj_labels[1])\n",
    "print(train_out_labels[1])\n",
    "print(train_geo_feat[1])\n",
    "print(\"\\n...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Shape of values (9180,) \n\nUnique labels:\n ['above' 'against' 'along' 'around' 'at_the_level_of' 'behind' 'beyond'\n 'far from' 'in' 'in_front_of' 'near' 'next_to' 'none' 'on' 'opposite'\n 'outside_of' 'under'] \n\nExample of One-Hot Encoded:\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.] \n\nConsider first example\n\nOutput Labels:\n [['next_to']\n ['at_the_level_of']\n ['near']]\n\nOne-Hot encoded labels:\n[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Example \n",
    "# Learning the one-hot encoder\n",
    "\n",
    "# read all prepositions in multilabel examples and flatten\n",
    "all_preps=[]\n",
    "for Y in data['development']['output_labels']:\n",
    "    for y in Y:\n",
    "        all_preps.append(y)\n",
    "\n",
    "values = np.array(all_preps).reshape(len(all_preps),)\n",
    "print(\"Shape of values\", values.shape,'\\n')\n",
    "\n",
    "# integer encode\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(values)\n",
    "print(\"Unique labels:\\n\",label_encoder.classes_,'\\n')\n",
    "\n",
    "# onehot encode\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "print(\"Example of One-Hot Encoded:\\n\", onehot_encoded[0],'\\n')\n",
    "\n",
    "# single label encoding for first example\n",
    "print(\"Consider first example\\n\")\n",
    "b = np.array(data['development']['output_labels'][0])\n",
    "b = b.reshape(len(b),1)\n",
    "print(\"Output Labels:\\n\",b)\n",
    "print(\"\\nOne-Hot encoded labels:\")\n",
    "for i in b:\n",
    "    a = label_encoder.transform(i)\n",
    "    print(onehot_encoder.transform(a.reshape(-1, 1))[0])\n",
    "\n"
   ]
  },
  {
   "source": [
    "# Section 1: Preparing the data\n",
    "\n",
    "## Part 1"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Answer to 1.a:\nMean output labels per row (train set):  2.1584763696214435\nMean output labels per row (test set):  2.148496240601504\n"
     ]
    }
   ],
   "source": [
    "# 1.a. Computing the mean output label count per example, per dataset (development and test)\n",
    "average_out_count_train = 0\n",
    "average_out_count_test = 0\n",
    "\n",
    "for row in train_out_labels:\n",
    "    average_out_count_train += len(row)\n",
    "for row in test_out_labels:\n",
    "    average_out_count_test += len(row)\n",
    "\n",
    "average_out_count_train /= len(train_out_labels)\n",
    "average_out_count_test /= len(test_out_labels)\n",
    "\n",
    "print('Answer to 1.a:')\n",
    "print('Mean output labels per row (train set): ', average_out_count_train)\n",
    "print ('Mean output labels per row (test set): ', average_out_count_test)\n",
    "\n",
    "saveAnswer({\n",
    "    'train_average_out': average_out_count_train,\n",
    "    'test_average_out': average_out_count_test\n",
    "}, '1a')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Results for 1.b:\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "                                                  0\nLabel distribution in development (train) set      \nnext_to                                        1411\nat_the_level_of                                 926\nnear                                           2276\nbehind                                         1055\nopposite                                        267\non                                              359\nin_front_of                                    1102\nabove                                           117\nunder                                           432\nfar from                                        376\nagainst                                         593\noutside_of                                       43\nbeyond                                           42\naround                                           34\nin                                               56\nalong                                            69\nnone                                             22",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n    <tr>\n      <th>Label distribution in development (train) set</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>next_to</th>\n      <td>1411</td>\n    </tr>\n    <tr>\n      <th>at_the_level_of</th>\n      <td>926</td>\n    </tr>\n    <tr>\n      <th>near</th>\n      <td>2276</td>\n    </tr>\n    <tr>\n      <th>behind</th>\n      <td>1055</td>\n    </tr>\n    <tr>\n      <th>opposite</th>\n      <td>267</td>\n    </tr>\n    <tr>\n      <th>on</th>\n      <td>359</td>\n    </tr>\n    <tr>\n      <th>in_front_of</th>\n      <td>1102</td>\n    </tr>\n    <tr>\n      <th>above</th>\n      <td>117</td>\n    </tr>\n    <tr>\n      <th>under</th>\n      <td>432</td>\n    </tr>\n    <tr>\n      <th>far from</th>\n      <td>376</td>\n    </tr>\n    <tr>\n      <th>against</th>\n      <td>593</td>\n    </tr>\n    <tr>\n      <th>outside_of</th>\n      <td>43</td>\n    </tr>\n    <tr>\n      <th>beyond</th>\n      <td>42</td>\n    </tr>\n    <tr>\n      <th>around</th>\n      <td>34</td>\n    </tr>\n    <tr>\n      <th>in</th>\n      <td>56</td>\n    </tr>\n    <tr>\n      <th>along</th>\n      <td>69</td>\n    </tr>\n    <tr>\n      <th>none</th>\n      <td>22</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "                                  0\nLabel distribution in test set     \nin_front_of                     270\nagainst                         136\nnext_to                         359\nat_the_level_of                 227\nnear                            578\nunder                           101\nbehind                          270\nfar from                        100\non                               88\nopposite                         66\nabove                            31\nalong                            16\nbeyond                            5\naround                            8\nin                               18\noutside_of                        8\nnone                              5",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n    <tr>\n      <th>Label distribution in test set</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>in_front_of</th>\n      <td>270</td>\n    </tr>\n    <tr>\n      <th>against</th>\n      <td>136</td>\n    </tr>\n    <tr>\n      <th>next_to</th>\n      <td>359</td>\n    </tr>\n    <tr>\n      <th>at_the_level_of</th>\n      <td>227</td>\n    </tr>\n    <tr>\n      <th>near</th>\n      <td>578</td>\n    </tr>\n    <tr>\n      <th>under</th>\n      <td>101</td>\n    </tr>\n    <tr>\n      <th>behind</th>\n      <td>270</td>\n    </tr>\n    <tr>\n      <th>far from</th>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>on</th>\n      <td>88</td>\n    </tr>\n    <tr>\n      <th>opposite</th>\n      <td>66</td>\n    </tr>\n    <tr>\n      <th>above</th>\n      <td>31</td>\n    </tr>\n    <tr>\n      <th>along</th>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>beyond</th>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>around</th>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>in</th>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>outside_of</th>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>none</th>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "# 1.b. Flatten the output labels to a 1-d array, computing the distribution for both datasets\n",
    "\n",
    "# Flatten the labels into a 1D array\n",
    "flat_out_train = np.concatenate(train_out_labels)\n",
    "flat_out_test = np.concatenate(test_out_labels)\n",
    "\n",
    "# Count the numbers of each label\n",
    "train_out_counts = Counter(flat_out_train)\n",
    "test_out_counts = Counter(flat_out_test)\n",
    "\n",
    "# Create dataframes from each counter object above.\n",
    "train_out_counts_df = pandas.DataFrame.from_dict(train_out_counts, orient='index')\n",
    "train_out_counts_df.index.name = 'Label distribution in development (train) set'\n",
    "test_out_counts_df = pandas.DataFrame.from_dict(test_out_counts, orient='index')\n",
    "test_out_counts_df.index.name = 'Label distribution in test set'\n",
    "\n",
    "print(\"Results for 1.b:\")\n",
    "display(train_out_counts_df)\n",
    "display(test_out_counts_df)\n",
    "\n",
    "saveAnswer({\n",
    "    'train_out_counts': train_out_counts_df,\n",
    "    'test_out_counts': test_out_counts_df\n",
    "}, '1b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Results for 1.c:\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "                                                      0\nComposite output label distribution in developm...     \n(next_to, at_the_level_of, near)                    509\n(behind, opposite, near)                              3\n(on,)                                               135\n(in_front_of, near)                                 269\n(near, behind)                                       31\n...                                                 ...\n(opposite, beyond)                                    1\n(in_front_of, opposite, under)                        1\n(outside_of, next_to, at_the_level_of, near)          1\n(in_front_of, next_to, opposite, near)                1\n(against, at_the_level_of)                            1\n\n[317 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n    <tr>\n      <th>Composite output label distribution in development (train) set</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>(next_to, at_the_level_of, near)</th>\n      <td>509</td>\n    </tr>\n    <tr>\n      <th>(behind, opposite, near)</th>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>(on,)</th>\n      <td>135</td>\n    </tr>\n    <tr>\n      <th>(in_front_of, near)</th>\n      <td>269</td>\n    </tr>\n    <tr>\n      <th>(near, behind)</th>\n      <td>31</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>(opposite, beyond)</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>(in_front_of, opposite, under)</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>(outside_of, next_to, at_the_level_of, near)</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>(in_front_of, next_to, opposite, near)</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>(against, at_the_level_of)</th>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>317 rows × 1 columns</p>\n</div>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "                                                   0\nComposite output label distribution in test set     \n(in_front_of, against)                             7\n(next_to, at_the_level_of, near)                 132\n(under,)                                          53\n(at_the_level_of,)                                 9\n(in_front_of, next_to, at_the_level_of, near)      2\n...                                              ...\n(above, next_to, against, behind, near)            1\n(in, on)                                           1\n(in_front_of, next_to, against)                    1\n(around, against, near)                            1\n(next_to, at_the_level_of, far from)               1\n\n[166 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n    <tr>\n      <th>Composite output label distribution in test set</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>(in_front_of, against)</th>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>(next_to, at_the_level_of, near)</th>\n      <td>132</td>\n    </tr>\n    <tr>\n      <th>(under,)</th>\n      <td>53</td>\n    </tr>\n    <tr>\n      <th>(at_the_level_of,)</th>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>(in_front_of, next_to, at_the_level_of, near)</th>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>(above, next_to, against, behind, near)</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>(in, on)</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>(in_front_of, next_to, against)</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>(around, against, near)</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>(next_to, at_the_level_of, far from)</th>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>166 rows × 1 columns</p>\n</div>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "# 1.c. Computing the composite output labels (without flattening like in 1.b) for both datasets.\n",
    "\n",
    "# Same as above, compute the occurances of each composite output label.\n",
    "# Unlike above, we first need to transform each row from an unhashable list to a hashable tuple object.\n",
    "train_cmp_out_counts = Counter(map(tuple, train_out_labels))\n",
    "test_cmp_out_counts = Counter(map(tuple, test_out_labels))\n",
    "\n",
    "train_cmp_out_counts_df = pandas.DataFrame.from_dict(train_cmp_out_counts, orient='index')\n",
    "train_cmp_out_counts_df.index.name = 'Composite output label distribution in development (train) set'\n",
    "test_cmp_out_counts_df = pandas.DataFrame.from_dict(test_cmp_out_counts, orient='index')\n",
    "test_cmp_out_counts_df.index.name = 'Composite output label distribution in test set'\n",
    "\n",
    "print('Results for 1.c:')\n",
    "display(train_cmp_out_counts_df)\n",
    "display(test_cmp_out_counts_df)\n",
    "\n",
    "saveAnswer({\n",
    "    'train_out_counts': train_cmp_out_counts_df,\n",
    "    'test_out_counts': test_cmp_out_counts_df\n",
    "}, '1c')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "                                above   against     along    around  \\\nco occurrence probabilities                                           \nabove                        0.000000  0.034188  0.000000  0.000000   \nagainst                      0.006745  0.000000  0.008432  0.008432   \nalong                        0.000000  0.072464  0.000000  0.000000   \naround                       0.000000  0.147059  0.000000  0.000000   \nat_the_level_of              0.006479  0.109071  0.019438  0.000000   \nbehind                       0.032227  0.067299  0.019905  0.001896   \nbeyond                       0.047619  0.023810  0.000000  0.000000   \nfar from                     0.026596  0.000000  0.002660  0.000000   \nin                           0.017857  0.232143  0.000000  0.000000   \nin_front_of                  0.012704  0.060799  0.019964  0.000000   \nnear                         0.029438  0.027241  0.023726  0.000000   \nnext_to                      0.017009  0.096386  0.039688  0.000000   \nnone                         0.000000  0.000000  0.000000  0.000000   \non                           0.013928  0.571031  0.000000  0.000000   \nopposite                     0.022472  0.041199  0.000000  0.000000   \noutside_of                   0.046512  0.069767  0.000000  0.000000   \nunder                        0.000000  0.324074  0.002315  0.016204   \n\n                             at_the_level_of    behind    beyond  far from  \\\nco occurrence probabilities                                                  \nabove                               0.051282  0.290598  0.017094  0.085470   \nagainst                             0.170320  0.119730  0.001686  0.000000   \nalong                               0.260870  0.304348  0.000000  0.014493   \naround                              0.000000  0.058824  0.000000  0.000000   \nat_the_level_of                     0.000000  0.032397  0.001080  0.019438   \nbehind                              0.028436  0.000000  0.023697  0.152607   \nbeyond                              0.023810  0.595238  0.000000  0.452381   \nfar from                            0.047872  0.428191  0.050532  0.000000   \nin                                  0.000000  0.000000  0.000000  0.000000   \nin_front_of                         0.036298  0.061706  0.009074  0.159710   \nnear                                0.315466  0.259227  0.002636  0.000439   \nnext_to                             0.532955  0.141035  0.000709  0.002126   \nnone                                0.000000  0.000000  0.000000  0.000000   \non                                  0.000000  0.002786  0.000000  0.000000   \nopposite                            0.172285  0.142322  0.011236  0.037453   \noutside_of                          0.093023  0.302326  0.000000  0.232558   \nunder                               0.011574  0.087963  0.002315  0.011574   \n\n                                   in  in_front_of      near   next_to  none  \\\nco occurrence probabilities                                                    \nabove                        0.008547     0.119658  0.572650  0.205128   0.0   \nagainst                      0.021922     0.112985  0.104553  0.229342   0.0   \nalong                        0.000000     0.318841  0.782609  0.811594   0.0   \naround                       0.000000     0.000000  0.000000  0.000000   0.0   \nat_the_level_of              0.000000     0.043197  0.775378  0.812095   0.0   \nbehind                       0.000000     0.064455  0.559242  0.188626   0.0   \nbeyond                       0.000000     0.238095  0.142857  0.023810   0.0   \nfar from                     0.000000     0.468085  0.002660  0.007979   0.0   \nin                           0.000000     0.000000  0.000000  0.000000   0.0   \nin_front_of                  0.000000     0.000000  0.545372  0.189655   0.0   \nnear                         0.000000     0.264060  0.000000  0.512742   0.0   \nnext_to                      0.000000     0.148122  0.827073  0.000000   0.0   \nnone                         0.000000     0.000000  0.000000  0.000000   0.0   \non                           0.069638     0.050139  0.036212  0.005571   0.0   \nopposite                     0.000000     0.269663  0.629213  0.179775   0.0   \noutside_of                   0.000000     0.395349  0.441860  0.302326   0.0   \nunder                        0.000000     0.067130  0.164352  0.046296   0.0   \n\n                                   on  opposite  outside_of     under  \nco occurrence probabilities                                            \nabove                        0.042735  0.051282    0.017094  0.000000  \nagainst                      0.345700  0.018550    0.005059  0.236088  \nalong                        0.000000  0.000000    0.000000  0.014493  \naround                       0.000000  0.000000    0.000000  0.205882  \nat_the_level_of              0.000000  0.049676    0.004320  0.005400  \nbehind                       0.000948  0.036019    0.012322  0.036019  \nbeyond                       0.000000  0.071429    0.000000  0.023810  \nfar from                     0.000000  0.026596    0.026596  0.013298  \nin                           0.446429  0.000000    0.000000  0.000000  \nin_front_of                  0.016334  0.065336    0.015426  0.026316  \nnear                         0.005712  0.073814    0.008348  0.031195  \nnext_to                      0.001417  0.034018    0.009213  0.014174  \nnone                         0.000000  0.000000    0.000000  0.000000  \non                           0.000000  0.000000    0.000000  0.000000  \nopposite                     0.000000  0.000000    0.003745  0.018727  \noutside_of                   0.000000  0.023256    0.000000  0.000000  \nunder                        0.000000  0.011574    0.000000  0.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>above</th>\n      <th>against</th>\n      <th>along</th>\n      <th>around</th>\n      <th>at_the_level_of</th>\n      <th>behind</th>\n      <th>beyond</th>\n      <th>far from</th>\n      <th>in</th>\n      <th>in_front_of</th>\n      <th>near</th>\n      <th>next_to</th>\n      <th>none</th>\n      <th>on</th>\n      <th>opposite</th>\n      <th>outside_of</th>\n      <th>under</th>\n    </tr>\n    <tr>\n      <th>co occurrence probabilities</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>above</th>\n      <td>0.000000</td>\n      <td>0.034188</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.051282</td>\n      <td>0.290598</td>\n      <td>0.017094</td>\n      <td>0.085470</td>\n      <td>0.008547</td>\n      <td>0.119658</td>\n      <td>0.572650</td>\n      <td>0.205128</td>\n      <td>0.0</td>\n      <td>0.042735</td>\n      <td>0.051282</td>\n      <td>0.017094</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>against</th>\n      <td>0.006745</td>\n      <td>0.000000</td>\n      <td>0.008432</td>\n      <td>0.008432</td>\n      <td>0.170320</td>\n      <td>0.119730</td>\n      <td>0.001686</td>\n      <td>0.000000</td>\n      <td>0.021922</td>\n      <td>0.112985</td>\n      <td>0.104553</td>\n      <td>0.229342</td>\n      <td>0.0</td>\n      <td>0.345700</td>\n      <td>0.018550</td>\n      <td>0.005059</td>\n      <td>0.236088</td>\n    </tr>\n    <tr>\n      <th>along</th>\n      <td>0.000000</td>\n      <td>0.072464</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.260870</td>\n      <td>0.304348</td>\n      <td>0.000000</td>\n      <td>0.014493</td>\n      <td>0.000000</td>\n      <td>0.318841</td>\n      <td>0.782609</td>\n      <td>0.811594</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.014493</td>\n    </tr>\n    <tr>\n      <th>around</th>\n      <td>0.000000</td>\n      <td>0.147059</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.058824</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.205882</td>\n    </tr>\n    <tr>\n      <th>at_the_level_of</th>\n      <td>0.006479</td>\n      <td>0.109071</td>\n      <td>0.019438</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.032397</td>\n      <td>0.001080</td>\n      <td>0.019438</td>\n      <td>0.000000</td>\n      <td>0.043197</td>\n      <td>0.775378</td>\n      <td>0.812095</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.049676</td>\n      <td>0.004320</td>\n      <td>0.005400</td>\n    </tr>\n    <tr>\n      <th>behind</th>\n      <td>0.032227</td>\n      <td>0.067299</td>\n      <td>0.019905</td>\n      <td>0.001896</td>\n      <td>0.028436</td>\n      <td>0.000000</td>\n      <td>0.023697</td>\n      <td>0.152607</td>\n      <td>0.000000</td>\n      <td>0.064455</td>\n      <td>0.559242</td>\n      <td>0.188626</td>\n      <td>0.0</td>\n      <td>0.000948</td>\n      <td>0.036019</td>\n      <td>0.012322</td>\n      <td>0.036019</td>\n    </tr>\n    <tr>\n      <th>beyond</th>\n      <td>0.047619</td>\n      <td>0.023810</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.023810</td>\n      <td>0.595238</td>\n      <td>0.000000</td>\n      <td>0.452381</td>\n      <td>0.000000</td>\n      <td>0.238095</td>\n      <td>0.142857</td>\n      <td>0.023810</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.071429</td>\n      <td>0.000000</td>\n      <td>0.023810</td>\n    </tr>\n    <tr>\n      <th>far from</th>\n      <td>0.026596</td>\n      <td>0.000000</td>\n      <td>0.002660</td>\n      <td>0.000000</td>\n      <td>0.047872</td>\n      <td>0.428191</td>\n      <td>0.050532</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.468085</td>\n      <td>0.002660</td>\n      <td>0.007979</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.026596</td>\n      <td>0.026596</td>\n      <td>0.013298</td>\n    </tr>\n    <tr>\n      <th>in</th>\n      <td>0.017857</td>\n      <td>0.232143</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.446429</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>in_front_of</th>\n      <td>0.012704</td>\n      <td>0.060799</td>\n      <td>0.019964</td>\n      <td>0.000000</td>\n      <td>0.036298</td>\n      <td>0.061706</td>\n      <td>0.009074</td>\n      <td>0.159710</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.545372</td>\n      <td>0.189655</td>\n      <td>0.0</td>\n      <td>0.016334</td>\n      <td>0.065336</td>\n      <td>0.015426</td>\n      <td>0.026316</td>\n    </tr>\n    <tr>\n      <th>near</th>\n      <td>0.029438</td>\n      <td>0.027241</td>\n      <td>0.023726</td>\n      <td>0.000000</td>\n      <td>0.315466</td>\n      <td>0.259227</td>\n      <td>0.002636</td>\n      <td>0.000439</td>\n      <td>0.000000</td>\n      <td>0.264060</td>\n      <td>0.000000</td>\n      <td>0.512742</td>\n      <td>0.0</td>\n      <td>0.005712</td>\n      <td>0.073814</td>\n      <td>0.008348</td>\n      <td>0.031195</td>\n    </tr>\n    <tr>\n      <th>next_to</th>\n      <td>0.017009</td>\n      <td>0.096386</td>\n      <td>0.039688</td>\n      <td>0.000000</td>\n      <td>0.532955</td>\n      <td>0.141035</td>\n      <td>0.000709</td>\n      <td>0.002126</td>\n      <td>0.000000</td>\n      <td>0.148122</td>\n      <td>0.827073</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.001417</td>\n      <td>0.034018</td>\n      <td>0.009213</td>\n      <td>0.014174</td>\n    </tr>\n    <tr>\n      <th>none</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>on</th>\n      <td>0.013928</td>\n      <td>0.571031</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.002786</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.069638</td>\n      <td>0.050139</td>\n      <td>0.036212</td>\n      <td>0.005571</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>opposite</th>\n      <td>0.022472</td>\n      <td>0.041199</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.172285</td>\n      <td>0.142322</td>\n      <td>0.011236</td>\n      <td>0.037453</td>\n      <td>0.000000</td>\n      <td>0.269663</td>\n      <td>0.629213</td>\n      <td>0.179775</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.003745</td>\n      <td>0.018727</td>\n    </tr>\n    <tr>\n      <th>outside_of</th>\n      <td>0.046512</td>\n      <td>0.069767</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.093023</td>\n      <td>0.302326</td>\n      <td>0.000000</td>\n      <td>0.232558</td>\n      <td>0.000000</td>\n      <td>0.395349</td>\n      <td>0.441860</td>\n      <td>0.302326</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.023256</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>under</th>\n      <td>0.000000</td>\n      <td>0.324074</td>\n      <td>0.002315</td>\n      <td>0.016204</td>\n      <td>0.011574</td>\n      <td>0.087963</td>\n      <td>0.002315</td>\n      <td>0.011574</td>\n      <td>0.000000</td>\n      <td>0.067130</td>\n      <td>0.164352</td>\n      <td>0.046296</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.011574</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "# 1.d Computing the co occurrence probability distribution of the training set.\n",
    "\n",
    "def computeProbabilityMatrix(matrix):\n",
    "    # Get all the unique labels from the input matrix.\n",
    "    labels = np.unique(np.concatenate(train_out_labels))\n",
    "\n",
    "    # Create the output matrix for the probabilities.\n",
    "    distribution = pd.DataFrame(np.zeros(((len(labels)), (len(labels)))), columns=labels, index=labels)\n",
    "    distribution.index.name = 'co occurrence probabilities'\n",
    "\n",
    "    # Get all co occurrences\n",
    "    for sample in matrix:\n",
    "        for target in labels:\n",
    "            if target in sample:\n",
    "                for prep in sample:\n",
    "                    distribution[target][prep] += 1\n",
    "\n",
    "    targetCount = 0\n",
    "    coCount = 0\n",
    "\n",
    "    # Calculate the probabilities by dividing the 2nd labels co occurrences with the 1st labels total occurrences\n",
    "    for target in labels:\n",
    "        for prep in [label for label in labels if label != target]:\n",
    "            targetCount = distribution[target][target]\n",
    "            coCount = distribution[prep][target]\n",
    "\n",
    "            distribution[prep][target] = coCount / targetCount\n",
    "        \n",
    "        # Set the targets to 0 to avoid bias\n",
    "        distribution[target][target] = 0\n",
    "\n",
    "\n",
    "    return distribution\n",
    "\n",
    "matrix = computeProbabilityMatrix(train_out_labels)\n",
    "\n",
    "display(matrix)\n",
    "\n",
    "saveAnswer({\n",
    "    'coOccurrenceProbMatrix': matrix\n",
    "}, '1.d')"
   ]
  },
  {
   "source": [
    "## Part 2"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#2.a Transform the object and geometrical features into an input matrix.\n",
    "\n",
    "# Trim the file names from the inputs.\n",
    "train_trimmed = np.array(train_obj_labels)[:, 1:]\n",
    "test_trimmed = np.array(test_obj_labels)[:, 1:]\n",
    "\n",
    "# Transform the features into one-hot encoded.\n",
    "obj_encoder = OneHotEncoder(sparse=False)\n",
    "obj_encoder = obj_encoder.fit(train_trimmed)\n",
    "train_input_matrix = obj_encoder.transform(train_trimmed)\n",
    "test_input_matrix = obj_encoder.transform(test_trimmed)\n",
    "\n",
    "# Append the geometrical features onto the obtained one-hot features.\n",
    "train_input_matrix = np.append(train_input_matrix, train_geo_feat, axis=1)\n",
    "test_input_matrix = np.append(test_input_matrix, test_geo_feat, axis=1)\n",
    "\n",
    "saveAnswer({\n",
    "    'train_input_matrix': train_input_matrix,\n",
    "    'test_input_matrix': test_input_matrix\n",
    "}, '2.a')\n",
    "\n",
    "XTrain = train_input_matrix\n",
    "XTest = test_input_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.b Transform the output features into a multi-label output matrix.\n",
    "\n",
    "# Use a multi-label binarizer to one-hot encode and reduce multiple features into a single vector.\n",
    "out_one_hot = MultiLabelBinarizer()\n",
    "out_one_hot = out_one_hot.fit(train_out_labels)\n",
    "\n",
    "train_output_matrix = out_one_hot.transform(train_out_labels)\n",
    "test_output_matrix = out_one_hot.transform(test_out_labels)\n",
    "\n",
    "saveAnswer({\n",
    "    'train_output_matrix': train_output_matrix,\n",
    "    'test_output_matrix': test_output_matrix\n",
    "}, '2.b')\n",
    "\n",
    "yTrain = train_output_matrix\n",
    "yTest = test_output_matrix"
   ]
  },
  {
   "source": [
    "## Part 3\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 Functions for calculating accuracy metrics\n",
    "\n",
    "def getMatrix(predictions, truths):\n",
    "    # Generate a single confusion matrix for all labels\n",
    "    tp = 0\n",
    "    fp = 1\n",
    "    fn = 2\n",
    "    tn = 3\n",
    "\n",
    "    # Initialise an empty array.\n",
    "    matrix = [0, 0, 0, 0]\n",
    "\n",
    "    # Over each prediction-truth pair, update the confusion matrix for that label.\n",
    "    for (plabel, tlabel) in np.nditer([predictions, truths], flags=['refs_ok']):\n",
    "        if plabel == 1 and tlabel == 1: matrix[tp] += 1\n",
    "        elif plabel == 1 and tlabel == 0: matrix[fp] += 1\n",
    "        elif plabel == 0 and tlabel == 1: matrix[fn] += 1\n",
    "        elif plabel == 0 and tlabel == 0: matrix[tn] += 1\n",
    "\n",
    "    return matrix\n",
    "\n",
    "def getMatrices(predictions, truths, num_labels):\n",
    "    # Generate a multi-label confusion matrix\n",
    "    tp = 0\n",
    "    fp = 1\n",
    "    fn = 2\n",
    "    tn = 3\n",
    "\n",
    "    # Initialise an empty set of arrays.\n",
    "    matrices = [[0, 0, 0, 0] for i in range(0, num_labels)]\n",
    "\n",
    "    it = np.nditer([predictions, truths], flags=['multi_index', 'refs_ok'])\n",
    "\n",
    "    # Over each prediction-truth pair, update the confusion matrix for that label.\n",
    "    for plabel, tlabel in it:\n",
    "        i = it.multi_index[1] # This is the label index\n",
    "        if plabel == 1 and tlabel == 1: matrices[i][tp] += 1\n",
    "        elif plabel == 1 and tlabel == 0: matrices[i][fp] += 1\n",
    "        elif plabel == 0 and tlabel == 1: matrices[i][fn] += 1\n",
    "        elif plabel == 0 and tlabel == 0: matrices[i][tn] += 1\n",
    "\n",
    "    return matrices\n",
    "\n",
    "# 3.a Accuracy (intersection over union)\n",
    "def getAccuracy(predictions, truths):\n",
    "    # Get the overall accuracy\n",
    "    matrix = getMatrix(predictions, truths)\n",
    "    \n",
    "    correct = matrix[0] + matrix[3] # tp + tn\n",
    "    total = sum(matrix) # tp + fp + fn + tn\n",
    "    \n",
    "    return correct / total\n",
    "\n",
    "# 3.b Precision\n",
    "def getPrecision(predictions, truths):\n",
    "    # Get the overall precision\n",
    "    matrix = getMatrix(predictions, truths)\n",
    "\n",
    "    positives = matrix[0] # tp\n",
    "    positiveGuesses = matrix[0] + matrix[1] # tp + fp\n",
    "\n",
    "    return positives / positiveGuesses\n",
    "\n",
    "# 3.c Recall\n",
    "def getRecall(predictions, truths):\n",
    "    # Get the overall recall\n",
    "    matrix = getMatrix(predictions, truths)\n",
    "\n",
    "    positives = matrix[0] # tp\n",
    "    allPositives = matrix[0] + matrix[2] # tp + fn\n",
    "    \n",
    "    return positives / allPositives\n",
    "\n",
    "# 3.d Per-label precision\n",
    "def getMultiLabelPrecision(predictions, truths):\n",
    "    # Get the per-label precision\n",
    "    matrices = getMatrices(predictions, truths, len(truths[0]))\n",
    "\n",
    "    precisions = [0 for i in range(len(matrices))]\n",
    "\n",
    "    for i, (tp, fp, fn, tn) in enumerate(matrices):\n",
    "        p = tp + fp\n",
    "        precisions[i] = (tp / p) if p != 0 else 1.0\n",
    "    \n",
    "    return precisions\n",
    "\n",
    "# 3.e Per-label recall\n",
    "def getMultiLabelRecall(predictions, truths):\n",
    "    # Get the per-label recall\n",
    "    matrices = getMatrices(predictions, truths, len(truths[0]))\n",
    "\n",
    "    recalls = [0 for i in range(len(matrices))]\n",
    "    \n",
    "    for i, (tp, fp, fn, tn) in enumerate(matrices):\n",
    "        allPositives = tp + fn\n",
    "        recalls[i] = (tp / allPositives) if allPositives != 0 else 1.0\n",
    "    \n",
    "    return recalls"
   ]
  },
  {
   "source": [
    "# Section 2\n",
    "\n",
    "## Part 1\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=4)]: Done 180 out of 180 | elapsed:  5.7min finished\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "{'classifier': LogisticRegression(max_iter=500, random_state=12, solver='sag', warm_start=True),\n 'classifier__C': 1.0,\n 'classifier__class_weight': None,\n 'classifier__max_iter': 500,\n 'classifier__random_state': 12,\n 'classifier__solver': 'sag',\n 'classifier__warm_start': True}"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "0.0338582981958941"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best estimator achieved an accuracy score of 0.0338582981958941 and trained in 11.24 sec\n"
     ]
    }
   ],
   "source": [
    "# 4.a Develop a binary-relevance model set using logistic regression, first trained through cross-validation and then training the best br model on the whole training set.\n",
    "\n",
    "parameters = [\n",
    "    {\n",
    "        'classifier': [LogisticRegression()],\n",
    "        'classifier__solver': ['sag', 'saga'],\n",
    "        'classifier__C': [1.0, 0.5, 1.5],\n",
    "        'classifier__max_iter': [250, 500, 100],\n",
    "        'classifier__class_weight': [None, 'balanced'],\n",
    "        'classifier__warm_start': [True],\n",
    "        'classifier__random_state': [12]\n",
    "    }\n",
    "]\n",
    "\n",
    "clf = GridSearchCV(BinaryRelevance(), parameters, scoring='accuracy', verbose=2, n_jobs=4)\n",
    "\n",
    "clf.fit(XTrain, yTrain)\n",
    "\n",
    "display(clf.best_params_, clf.best_score_)\n",
    "print(f'Best estimator achieved an accuracy score of {clf.best_score_} and trained in {clf.refit_time_:.2f} sec')\n",
    "\n",
    "predictions = clf.predict(XTest).todense()\n",
    "\n",
    "saveAnswer({\n",
    "    'trained_model': clf,\n",
    "    'predictions': predictions\n",
    "}, '4.a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy: 0.8857253427686864\nPrecision: 0.6102719033232629\nRecall: 0.2650918635170604\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "                 Precision\nabove             1.000000\nagainst           1.000000\nalong             1.000000\naround            1.000000\nat_the_level_of   1.000000\nbehind            0.681818\nbeyond            1.000000\nfar from          0.625000\nin                1.000000\nin_front_of       0.672131\nnear              0.597605\nnext_to           1.000000\nnone              1.000000\non                1.000000\nopposite          1.000000\noutside_of        1.000000\nunder             1.000000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Precision</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>above</th>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>against</th>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>along</th>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>around</th>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>at_the_level_of</th>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>behind</th>\n      <td>0.681818</td>\n    </tr>\n    <tr>\n      <th>beyond</th>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>far from</th>\n      <td>0.625000</td>\n    </tr>\n    <tr>\n      <th>in</th>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>in_front_of</th>\n      <td>0.672131</td>\n    </tr>\n    <tr>\n      <th>near</th>\n      <td>0.597605</td>\n    </tr>\n    <tr>\n      <th>next_to</th>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>none</th>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>on</th>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>opposite</th>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>outside_of</th>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>under</th>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "                   Recall\nabove            0.000000\nagainst          0.000000\nalong            0.000000\naround           0.000000\nat_the_level_of  0.000000\nbehind           0.222222\nbeyond           0.000000\nfar from         0.050000\nin               0.000000\nin_front_of      0.151852\nnear             0.863322\nnext_to          0.000000\nnone             0.000000\non               0.000000\nopposite         0.000000\noutside_of       0.000000\nunder            0.009901",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>above</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>against</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>along</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>around</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>at_the_level_of</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>behind</th>\n      <td>0.222222</td>\n    </tr>\n    <tr>\n      <th>beyond</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>far from</th>\n      <td>0.050000</td>\n    </tr>\n    <tr>\n      <th>in</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>in_front_of</th>\n      <td>0.151852</td>\n    </tr>\n    <tr>\n      <th>near</th>\n      <td>0.863322</td>\n    </tr>\n    <tr>\n      <th>next_to</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>none</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>on</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>opposite</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>outside_of</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>under</th>\n      <td>0.009901</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "# 4.b Metrics on the trained models from 4.a\n",
    "\n",
    "\n",
    "# Next, compute the metrics accordingly.\n",
    "acc = getAccuracy(predictions, yTest)\n",
    "pre = getPrecision(predictions, yTest)\n",
    "rec = getRecall(predictions, yTest)\n",
    "prePerLabel = getMultiLabelPrecision(predictions, yTest)\n",
    "recPerLabel = getMultiLabelRecall(predictions, yTest)\n",
    "\n",
    "# In the case of the multi-label metrics, convert them into dataframes for readability.\n",
    "prePerLabel = pd.DataFrame(prePerLabel, index=out_one_hot.classes_, columns=['Precision'])\n",
    "recPerLabel = pd.DataFrame(recPerLabel, index=out_one_hot.classes_, columns=['Recall'])\n",
    "\n",
    "print(f'Accuracy: {acc}')\n",
    "print(f'Precision: {pre}')\n",
    "print(f'Recall: {rec}')\n",
    "display(prePerLabel)\n",
    "display(recPerLabel)\n",
    "\n",
    "saveAnswer({\n",
    "    'accuracy': acc,\n",
    "    'precision': pre,\n",
    "    'recall': rec,\n",
    "    'multiPrecision': prePerLabel,\n",
    "    'recPerLabel': recPerLabel\n",
    "}, '4.b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}