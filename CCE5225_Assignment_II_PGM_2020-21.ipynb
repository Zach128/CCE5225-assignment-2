{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment - Probabilistic Graphical Models\n",
    "### Year 2020-2021- Semester I\n",
    "### CCE5225\n",
    "####  Developed by - Adrian Muscat, 2020\n",
    "---\n",
    "Zachary Cauchi, 197999M, BSc CS, Yr I\n",
    "\n",
    "Submit a pdf version (with the attached plagiarism form) of the final jupyter notebook (as a turn-it-in job on VLE) and the jupyter notebook itself separately (as an assignment job on VLE)\n",
    "\n",
    "This assignment is to be attempted individually. It is essential that the work you submit and present consists only of your own work; use of copied material will be treated as plagiarism. Discussion is only permitted on general issues, and it is absolutely forbidden to discuss specific details with anyone and/or share results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = open('MLC_data_2020_21.pkl','rb')\n",
    "data = pickle.load(infile, encoding='latin1')\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "First split is into : dict_keys(['development', 'test']) \n\nThe three lists are dict_keys(['object_labels', 'output_labels', 'geometric_features']) \n\nThere are 4253 examples in dev set\n\nFirst example:\n['2008_001130.jpg', 'tvmonitor', 'bottle']\n['next_to', 'at_the_level_of', 'near']\n[ 0.68888274  0.07051991  0.          0.88679245  0.39215686  0.63316053\n  0.109375    1.36170213  1.14893617  1.06603774  0.58490566  9.76862745\n  0.5546875  -0.30530973]\n\nSecond example:\n['2008_002210.jpg', 'person_2', 'diningtable']\n['behind', 'opposite', 'near']\n[ 0.43984962  0.28696742  0.16        0.40206186  2.36082474  0.48306117\n  0.          2.27350427  0.31623932  1.          0.66666667  1.53275109\n  0.34962406 -0.33333333]\n\n...\n"
     ]
    }
   ],
   "source": [
    "# Explore dataset\n",
    "print(\"First split is into :\",data.keys(),'\\n')\n",
    "#\n",
    "# Lets explore the development set\n",
    "# This is organised into three lists\n",
    "print(\"The three lists are\",data['development'].keys(),'\\n')\n",
    "#\n",
    "# The first element of each list corresponds to the object_labels, \n",
    "# geomteric features and output labels for the first example\n",
    "# ...and so on\n",
    "# Lets explore the first example\n",
    "train_obj_labels = data['development']['object_labels']\n",
    "train_out_labels = data['development']['output_labels']\n",
    "train_geo_feat = data['development']['geometric_features']\n",
    "test_obj_labels = data['test']['object_labels']\n",
    "test_out_labels = data['test']['output_labels']\n",
    "test_geo_feat = data['test']['geometric_features']\n",
    "print(\"There are\",len(train_obj_labels), \"examples in dev set\\n\")\n",
    "print(\"First example:\")\n",
    "print(train_obj_labels[0])\n",
    "print(train_out_labels[0])\n",
    "print(train_geo_feat[0])\n",
    "print(\"\\nSecond example:\")\n",
    "print(train_obj_labels[1])\n",
    "print(train_out_labels[1])\n",
    "print(train_geo_feat[1])\n",
    "print(\"\\n...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Shape of values (9180,) \n\nUnique labels:\n ['above' 'against' 'along' 'around' 'at_the_level_of' 'behind' 'beyond'\n 'far from' 'in' 'in_front_of' 'near' 'next_to' 'none' 'on' 'opposite'\n 'outside_of' 'under'] \n\nExample of One-Hot Encoded:\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.] \n\nConsider first example\n\nOutput Labels:\n [['next_to']\n ['at_the_level_of']\n ['near']]\n\nOne-Hot encoded labels:\n[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Example \n",
    "# Learning the one-hot encoder\n",
    "\n",
    "# read all prepositions in multilabel examples and flatten\n",
    "all_preps=[]\n",
    "for Y in data['development']['output_labels']:\n",
    "    for y in Y:\n",
    "        all_preps.append(y)\n",
    "\n",
    "values = np.array(all_preps).reshape(len(all_preps),)\n",
    "print(\"Shape of values\", values.shape,'\\n')\n",
    "\n",
    "# integer encode\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(values)\n",
    "print(\"Unique labels:\\n\",label_encoder.classes_,'\\n')\n",
    "\n",
    "# onehot encode\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "print(\"Example of One-Hot Encoded:\\n\", onehot_encoded[0],'\\n')\n",
    "\n",
    "# single label encoding for first example\n",
    "print(\"Consider first example\\n\")\n",
    "b = np.array(data['development']['output_labels'][0])\n",
    "b = b.reshape(len(b),1)\n",
    "print(\"Output Labels:\\n\",b)\n",
    "print(\"\\nOne-Hot encoded labels:\")\n",
    "for i in b:\n",
    "    a = label_encoder.transform(i)\n",
    "    print(onehot_encoder.transform(a.reshape(-1, 1))[0])\n",
    "\n"
   ]
  },
  {
   "source": [
    "# Section 1: Preparing the data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Answer to 1.a:\nMean output labels per row (train set):  2.1584763696214435\nMean output labels per row (test set):  2.148496240601504\n"
     ]
    }
   ],
   "source": [
    "# 1.a. Computing the mean output label count per example, per data set (development and test)\n",
    "average_out_count_train = 0\n",
    "average_out_count_test = 0\n",
    "\n",
    "for row in train_out_labels:\n",
    "    average_out_count_train += len(row)\n",
    "for row in test_out_labels:\n",
    "    average_out_count_test += len(row)\n",
    "\n",
    "average_out_count_train /= len(train_out_labels)\n",
    "average_out_count_test /= len(test_out_labels)\n",
    "\n",
    "print(\"Answer to 1.a:\")\n",
    "print(\"Mean output labels per row (train set): \", average_out_count_train)\n",
    "print (\"Mean output labels per row (test set): \", average_out_count_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}